/*Face detection with speech to text project

Concept

Facial Detection with Speech to Text is meant to help assist people in their everyday life, for
instance, education, work, etc. This project could be used in two ways, in particular, facial
detection could help businesses to detect if there are any customers in the store, and
speech to text could help workers, students to take notes.

Context

AI is related to both face detection and speech to text because they both use recognition
systems that help recognise someone. They all use a system where it scans human faces
and scans human voices. Speech to text is used for those who can't type or do not have time
to.

Speech to text

Artificial intelligence (AI) is now used in natural language processing (NLP), translation, and
speech recognition. Text-to-speech recognition is the process of converting audio to text
while a natural language processor (NLP) analyses the text to identify its meaning (Horowitz,
2020).

In 1962, the first speech recognition machine was released by IBM. Programs that are
voice-driven comparable to Microsoft's Cortana, Apple's Siri, Amazon's Alexa, and various
Google's voice-responsive features, speech recognition has become increasingly integrated
into our daily lives as technology has advanced. Each new voice-interactive device we bring
into our lives, from our phones to our computers, watches, and refrigerators, increases our
dependence on machine learning and artificial intelligence (ONPASSIVE Bill Must, 2021).

Voice technology has become an integral part of our daily life and is currently witnessing the
rapid evolution of artificial intelligence and data modelling technologies to work out intention
and emotion determined by speech. Almost half of all online searches were expected to
come from voice by the end of 2020. In a single day, an estimated 200 million users interact
through Microsoft Teams, although the advanced voice assist businesses cut down on time
by 40% of customer management (OTO Systems Inc, 2021).

Google Translate uses the speech to text by letting the user speak the desired language,
which then lets the app transcribe what has been said into another language. Google has
also used real-time conversation which allows users to execute back and forth
communication with another person, even if they don’t speak the same language (Whitney,
2020).

Face Detection

Machine learning approaches are used to detect objects throughout photographs, although
these methodologies are not taught systems because they are manually developed
algorithms. Deep Learning for Object Detection can be approached in two ways. The initial
step is to create the network architecture from scratch and train it. Secondly, use a
pre-trained network that has been trained on a large dataset before beginning your bespoke
dataset principles. Although compared to adopting an already-trained network, the next
strategy avoids the considerable time disadvantages associated with the first approach, so
that training a network from scratch takes significantly longer and requires far more effort
(Alake, 2020).

Face Match is the feature of Google's new Nest Hub Max that operates using a front camera
that always activates face detection and recognition algorithms to find out who is using it. It
works similar to Apple's FaceID, Android Face Unlock and identifies people using identical
software to Apple Photos, Facebook, and Google Photos (Smith, 2020).

Data mining is a technique for automatically and efficiently capturing patterns and features of
human faces. Each training image is first converted to an edge image using Sobel's edge
detection operator, threshold, and morphological operator. To obtain the positive feature
patterns, apply the Maximum Common Itemset algorithm (MAFIA) to determine the most
common patterns for these edge images / videos. For example, look at the MAFIA table
below. Similarly, borderless images, each of which is a complement to a border image, can
be used to generate the pattern of negative features. Develop a face detector with three
cascading classifiers to circumcise faceless candidates based on the patterns of positive and
negative traits extracted (Tsao, Lee, Liu, Chang & Lin, 2009).

To conclude everything in simple terms, the relation between face detection and speech to
text is that sooner or later in the future there might be an AI fully developed to detect whether
or not humans are dead or alive just by scanning their faces. The future of face detection
could take one of three forms: no regulation, some restriction, or outright prohibition. An
example of no regulation, cameras are all over the place, it's quite easy to imagine Orwellian
scenarios in which gadgets track you wherever you go by looking at your face.
Monitoring your activity on your computer or determining whether you sneaked off elsewhere
because you're an employee or a student, could be a simple way of observing to see if
you’re concentrating upon your job or procrastinating (Klosowski, 2020).


*/
